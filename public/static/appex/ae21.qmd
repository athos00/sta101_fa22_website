---
title: "Ethics in Statistics and Data Science"
subtitle: "STA 101"
format: html
---

## Bulletin

- [Lab 09](https://sta101-fa22.netlify.app/static/labs/lab09.html)
- This Friday is last lab before peer-review in two weeks

## Today

By the end of today you will...

- critically examine graphics, models and results
- discuss data privacy and redundancy
- analyze a real data example of Simpson's paradox

## Getting started

Download this application exercise by pasting the code below into your **console**

```
download.file("https://sta101-fa22.netlify.app/static/appex/ae21.qmd",
destfile = "ae21.qmd")
```

## Load packages

```{r load-libraries, message = F, warning = F}
library(tidyverse)
library(tidymodels)
```

### Guidelines for Discussion

- Listen respectfully. Listen actively and with an ear to understanding others’ views.

- Criticize ideas, not individuals.

- Commit to learning, not debating. Comment in order to share information, not to persuade.

- Avoid blame, speculation, and inflammatory language.

- Avoid assumptions about any member of the class or generalizations about social groups.

## Data Representation

### Misleading Data Visualizations^[Source: https://humansofdata.atlan.com/2019/02/dos-donts-data-visualization]

**Brexit**

![Brexit](https://sta101.github.io/static/img/brexit.png){width=50%}

- What is the graph trying to show?

- Why is this graph misleading?

- How can you improve this graph?

**Spurious Correlations**^[Source: https://www.tylervigen.com/spurious-correlations Content warning: some examples include death or suicide.]

![ A Spurious Correlation](https://sta101.github.io/static/img/spurious.png){ width=75%}

- What is the graph trying to show?

- Why is this graph misleading?

## Statistical modeling

Read, with a critical eye, page 2 and table 1 from [Physician–patient racial concordance and disparities inbirthing mortality for newborns](https://www.pnas.org/doi/epdf/10.1073/pnas.1913405117) and chat with your neighbor. 



## Data privacy

### Web scraping^[Modified from Modern Data Science with R, 2nd Edition]

A data analyst received permission to post a data set that was scraped from a social media site. The full data set included name, screen name, email address, geographic location, IP (Internet protocol) address, demographic profiles, and preferences for relationships. The analyst removes name and email address from the data set in effort to deidentify it.

- Why might it be problematic to post this data set publicly?

- How can you store the full dataset in a safe and ethical way?

- You want to make the data available so your analysis is transparent and reproducible. How can you modify the full data set to make the data available in an ethical way?

### Redundancy

- [slides](https://sta101-fa22.netlify.app/static/slides/ethics_Ezinne.pdf)

### Additional readings

- [Why pokemon go's plan to 3d scan the world is dangerous](https://www.sydney.edu.au/news-opinion/news/2020/06/18/why-pokemon-go-s-plan-to-3d-scan-the-world-is-dangerous.html)

- [How companies learn your secrets](https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html)


### Discussion questions

- "Simpson's paradox", where conclusions drawn from analyzing subgroups differ from conclusions drawn when the groups are combined. Can you demonstrate Simpson's Paradox with the data below? ^[Source:  https://www.randomservices.org/random/data/Berkeley.html]

- For further reading see [Bickel, Peter J., Eugene A. Hammel, and J. William O'Connell. "Sex Bias in Graduate Admissions: Data from Berkeley: Measuring bias is harder than is usually assumed, and the evidence is sometimes contrary to expectation." Science 187.4175 (1975): 398-404.](https://www.science.org/doi/abs/10.1126/science.187.4175.398)

```{r s-p, warning = F}
berk = read_csv("https://sta101.github.io/static/appex/data/BerkeleyAdmissionsData.csv")
berk

```
